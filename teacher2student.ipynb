{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load(\"output/FastPitch_checkpoint_teacher_100.pt\", map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['pitch_mean', 'pitch_std', 'encoder.word_emb.weight', 'encoder.pos_emb.inv_freq', 'encoder.layers.0.dec_attn.qkv_net.weight', 'encoder.layers.0.dec_attn.qkv_net.bias', 'encoder.layers.0.dec_attn.o_net.weight', 'encoder.layers.0.dec_attn.layer_norm.weight', 'encoder.layers.0.dec_attn.layer_norm.bias', 'encoder.layers.0.pos_ff.CoreNet.0.weight', 'encoder.layers.0.pos_ff.CoreNet.0.bias', 'encoder.layers.0.pos_ff.CoreNet.2.weight', 'encoder.layers.0.pos_ff.CoreNet.2.bias', 'encoder.layers.0.pos_ff.layer_norm.weight', 'encoder.layers.0.pos_ff.layer_norm.bias', 'encoder.layers.1.dec_attn.qkv_net.weight', 'encoder.layers.1.dec_attn.qkv_net.bias', 'encoder.layers.1.dec_attn.o_net.weight', 'encoder.layers.1.dec_attn.layer_norm.weight', 'encoder.layers.1.dec_attn.layer_norm.bias', 'encoder.layers.1.pos_ff.CoreNet.0.weight', 'encoder.layers.1.pos_ff.CoreNet.0.bias', 'encoder.layers.1.pos_ff.CoreNet.2.weight', 'encoder.layers.1.pos_ff.CoreNet.2.bias', 'encoder.layers.1.pos_ff.layer_norm.weight', 'encoder.layers.1.pos_ff.layer_norm.bias', 'encoder.layers.2.dec_attn.qkv_net.weight', 'encoder.layers.2.dec_attn.qkv_net.bias', 'encoder.layers.2.dec_attn.o_net.weight', 'encoder.layers.2.dec_attn.layer_norm.weight', 'encoder.layers.2.dec_attn.layer_norm.bias', 'encoder.layers.2.pos_ff.CoreNet.0.weight', 'encoder.layers.2.pos_ff.CoreNet.0.bias', 'encoder.layers.2.pos_ff.CoreNet.2.weight', 'encoder.layers.2.pos_ff.CoreNet.2.bias', 'encoder.layers.2.pos_ff.layer_norm.weight', 'encoder.layers.2.pos_ff.layer_norm.bias', 'encoder.layers.3.dec_attn.qkv_net.weight', 'encoder.layers.3.dec_attn.qkv_net.bias', 'encoder.layers.3.dec_attn.o_net.weight', 'encoder.layers.3.dec_attn.layer_norm.weight', 'encoder.layers.3.dec_attn.layer_norm.bias', 'encoder.layers.3.pos_ff.CoreNet.0.weight', 'encoder.layers.3.pos_ff.CoreNet.0.bias', 'encoder.layers.3.pos_ff.CoreNet.2.weight', 'encoder.layers.3.pos_ff.CoreNet.2.bias', 'encoder.layers.3.pos_ff.layer_norm.weight', 'encoder.layers.3.pos_ff.layer_norm.bias', 'encoder.layers.4.dec_attn.qkv_net.weight', 'encoder.layers.4.dec_attn.qkv_net.bias', 'encoder.layers.4.dec_attn.o_net.weight', 'encoder.layers.4.dec_attn.layer_norm.weight', 'encoder.layers.4.dec_attn.layer_norm.bias', 'encoder.layers.4.pos_ff.CoreNet.0.weight', 'encoder.layers.4.pos_ff.CoreNet.0.bias', 'encoder.layers.4.pos_ff.CoreNet.2.weight', 'encoder.layers.4.pos_ff.CoreNet.2.bias', 'encoder.layers.4.pos_ff.layer_norm.weight', 'encoder.layers.4.pos_ff.layer_norm.bias', 'encoder.layers.5.dec_attn.qkv_net.weight', 'encoder.layers.5.dec_attn.qkv_net.bias', 'encoder.layers.5.dec_attn.o_net.weight', 'encoder.layers.5.dec_attn.layer_norm.weight', 'encoder.layers.5.dec_attn.layer_norm.bias', 'encoder.layers.5.pos_ff.CoreNet.0.weight', 'encoder.layers.5.pos_ff.CoreNet.0.bias', 'encoder.layers.5.pos_ff.CoreNet.2.weight', 'encoder.layers.5.pos_ff.CoreNet.2.bias', 'encoder.layers.5.pos_ff.layer_norm.weight', 'encoder.layers.5.pos_ff.layer_norm.bias', 'duration_predictor.layers.0.conv.weight', 'duration_predictor.layers.0.conv.bias', 'duration_predictor.layers.0.norm.weight', 'duration_predictor.layers.0.norm.bias', 'duration_predictor.layers.1.conv.weight', 'duration_predictor.layers.1.conv.bias', 'duration_predictor.layers.1.norm.weight', 'duration_predictor.layers.1.norm.bias', 'duration_predictor.fc.weight', 'duration_predictor.fc.bias', 'decoder.pos_emb.inv_freq', 'decoder.layers.0.dec_attn.qkv_net.weight', 'decoder.layers.0.dec_attn.qkv_net.bias', 'decoder.layers.0.dec_attn.o_net.weight', 'decoder.layers.0.dec_attn.layer_norm.weight', 'decoder.layers.0.dec_attn.layer_norm.bias', 'decoder.layers.0.pos_ff.CoreNet.0.weight', 'decoder.layers.0.pos_ff.CoreNet.0.bias', 'decoder.layers.0.pos_ff.CoreNet.2.weight', 'decoder.layers.0.pos_ff.CoreNet.2.bias', 'decoder.layers.0.pos_ff.layer_norm.weight', 'decoder.layers.0.pos_ff.layer_norm.bias', 'decoder.layers.1.dec_attn.qkv_net.weight', 'decoder.layers.1.dec_attn.qkv_net.bias', 'decoder.layers.1.dec_attn.o_net.weight', 'decoder.layers.1.dec_attn.layer_norm.weight', 'decoder.layers.1.dec_attn.layer_norm.bias', 'decoder.layers.1.pos_ff.CoreNet.0.weight', 'decoder.layers.1.pos_ff.CoreNet.0.bias', 'decoder.layers.1.pos_ff.CoreNet.2.weight', 'decoder.layers.1.pos_ff.CoreNet.2.bias', 'decoder.layers.1.pos_ff.layer_norm.weight', 'decoder.layers.1.pos_ff.layer_norm.bias', 'decoder.layers.2.dec_attn.qkv_net.weight', 'decoder.layers.2.dec_attn.qkv_net.bias', 'decoder.layers.2.dec_attn.o_net.weight', 'decoder.layers.2.dec_attn.layer_norm.weight', 'decoder.layers.2.dec_attn.layer_norm.bias', 'decoder.layers.2.pos_ff.CoreNet.0.weight', 'decoder.layers.2.pos_ff.CoreNet.0.bias', 'decoder.layers.2.pos_ff.CoreNet.2.weight', 'decoder.layers.2.pos_ff.CoreNet.2.bias', 'decoder.layers.2.pos_ff.layer_norm.weight', 'decoder.layers.2.pos_ff.layer_norm.bias', 'decoder.layers.3.dec_attn.qkv_net.weight', 'decoder.layers.3.dec_attn.qkv_net.bias', 'decoder.layers.3.dec_attn.o_net.weight', 'decoder.layers.3.dec_attn.layer_norm.weight', 'decoder.layers.3.dec_attn.layer_norm.bias', 'decoder.layers.3.pos_ff.CoreNet.0.weight', 'decoder.layers.3.pos_ff.CoreNet.0.bias', 'decoder.layers.3.pos_ff.CoreNet.2.weight', 'decoder.layers.3.pos_ff.CoreNet.2.bias', 'decoder.layers.3.pos_ff.layer_norm.weight', 'decoder.layers.3.pos_ff.layer_norm.bias', 'decoder.layers.4.dec_attn.qkv_net.weight', 'decoder.layers.4.dec_attn.qkv_net.bias', 'decoder.layers.4.dec_attn.o_net.weight', 'decoder.layers.4.dec_attn.layer_norm.weight', 'decoder.layers.4.dec_attn.layer_norm.bias', 'decoder.layers.4.pos_ff.CoreNet.0.weight', 'decoder.layers.4.pos_ff.CoreNet.0.bias', 'decoder.layers.4.pos_ff.CoreNet.2.weight', 'decoder.layers.4.pos_ff.CoreNet.2.bias', 'decoder.layers.4.pos_ff.layer_norm.weight', 'decoder.layers.4.pos_ff.layer_norm.bias', 'decoder.layers.5.dec_attn.qkv_net.weight', 'decoder.layers.5.dec_attn.qkv_net.bias', 'decoder.layers.5.dec_attn.o_net.weight', 'decoder.layers.5.dec_attn.layer_norm.weight', 'decoder.layers.5.dec_attn.layer_norm.bias', 'decoder.layers.5.pos_ff.CoreNet.0.weight', 'decoder.layers.5.pos_ff.CoreNet.0.bias', 'decoder.layers.5.pos_ff.CoreNet.2.weight', 'decoder.layers.5.pos_ff.CoreNet.2.bias', 'decoder.layers.5.pos_ff.layer_norm.weight', 'decoder.layers.5.pos_ff.layer_norm.bias', 'pitch_predictor.layers.0.conv.weight', 'pitch_predictor.layers.0.conv.bias', 'pitch_predictor.layers.0.norm.weight', 'pitch_predictor.layers.0.norm.bias', 'pitch_predictor.layers.1.conv.weight', 'pitch_predictor.layers.1.conv.bias', 'pitch_predictor.layers.1.norm.weight', 'pitch_predictor.layers.1.norm.bias', 'pitch_predictor.fc.weight', 'pitch_predictor.fc.bias', 'pitch_emb.weight', 'pitch_emb.bias', 'energy_predictor.layers.0.conv.weight', 'energy_predictor.layers.0.conv.bias', 'energy_predictor.layers.0.norm.weight', 'energy_predictor.layers.0.norm.bias', 'energy_predictor.layers.1.conv.weight', 'energy_predictor.layers.1.conv.bias', 'energy_predictor.layers.1.norm.weight', 'energy_predictor.layers.1.norm.bias', 'energy_predictor.fc.weight', 'energy_predictor.fc.bias', 'energy_emb.weight', 'energy_emb.bias', 'proj.weight', 'proj.bias', 'attention.query_proj.0.conv.weight', 'attention.query_proj.0.conv.bias', 'attention.query_proj.2.conv.weight', 'attention.query_proj.2.conv.bias', 'attention.query_proj.4.conv.weight', 'attention.query_proj.4.conv.bias', 'attention.attn_proj.weight', 'attention.attn_proj.bias', 'attention.key_proj.0.conv.weight', 'attention.key_proj.0.conv.bias', 'attention.key_proj.2.conv.weight', 'attention.key_proj.2.conv.bias'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt[\"state_dict\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_layer_remove(layer_name):\n",
    "    if \"encoder.layers.1\" in layer_name:\n",
    "        return True\n",
    "    if \"encoder.layers.2\" in layer_name:\n",
    "        return True\n",
    "    if \"encoder.layers.4\" in layer_name:\n",
    "        return True\n",
    "    if \"encoder.layers.5\" in layer_name:\n",
    "        return True\n",
    "\n",
    "    if \"decoder.layers.1\" in layer_name:\n",
    "        return True\n",
    "    if \"decoder.layers.2\" in layer_name:\n",
    "        return True\n",
    "    if \"decoder.layers.4\" in layer_name:\n",
    "        return True\n",
    "    if \"decoder.layers.5\" in layer_name:\n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "    \n",
    "layer_to_remove = [i for i in ckpt[\"state_dict\"].keys() if check_layer_remove(i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['encoder.layers.1.dec_attn.qkv_net.weight',\n",
       " 'encoder.layers.1.dec_attn.qkv_net.bias',\n",
       " 'encoder.layers.1.dec_attn.o_net.weight',\n",
       " 'encoder.layers.1.dec_attn.layer_norm.weight',\n",
       " 'encoder.layers.1.dec_attn.layer_norm.bias',\n",
       " 'encoder.layers.1.pos_ff.CoreNet.0.weight',\n",
       " 'encoder.layers.1.pos_ff.CoreNet.0.bias',\n",
       " 'encoder.layers.1.pos_ff.CoreNet.2.weight',\n",
       " 'encoder.layers.1.pos_ff.CoreNet.2.bias',\n",
       " 'encoder.layers.1.pos_ff.layer_norm.weight',\n",
       " 'encoder.layers.1.pos_ff.layer_norm.bias',\n",
       " 'encoder.layers.2.dec_attn.qkv_net.weight',\n",
       " 'encoder.layers.2.dec_attn.qkv_net.bias',\n",
       " 'encoder.layers.2.dec_attn.o_net.weight',\n",
       " 'encoder.layers.2.dec_attn.layer_norm.weight',\n",
       " 'encoder.layers.2.dec_attn.layer_norm.bias',\n",
       " 'encoder.layers.2.pos_ff.CoreNet.0.weight',\n",
       " 'encoder.layers.2.pos_ff.CoreNet.0.bias',\n",
       " 'encoder.layers.2.pos_ff.CoreNet.2.weight',\n",
       " 'encoder.layers.2.pos_ff.CoreNet.2.bias',\n",
       " 'encoder.layers.2.pos_ff.layer_norm.weight',\n",
       " 'encoder.layers.2.pos_ff.layer_norm.bias',\n",
       " 'encoder.layers.4.dec_attn.qkv_net.weight',\n",
       " 'encoder.layers.4.dec_attn.qkv_net.bias',\n",
       " 'encoder.layers.4.dec_attn.o_net.weight',\n",
       " 'encoder.layers.4.dec_attn.layer_norm.weight',\n",
       " 'encoder.layers.4.dec_attn.layer_norm.bias',\n",
       " 'encoder.layers.4.pos_ff.CoreNet.0.weight',\n",
       " 'encoder.layers.4.pos_ff.CoreNet.0.bias',\n",
       " 'encoder.layers.4.pos_ff.CoreNet.2.weight',\n",
       " 'encoder.layers.4.pos_ff.CoreNet.2.bias',\n",
       " 'encoder.layers.4.pos_ff.layer_norm.weight',\n",
       " 'encoder.layers.4.pos_ff.layer_norm.bias',\n",
       " 'encoder.layers.5.dec_attn.qkv_net.weight',\n",
       " 'encoder.layers.5.dec_attn.qkv_net.bias',\n",
       " 'encoder.layers.5.dec_attn.o_net.weight',\n",
       " 'encoder.layers.5.dec_attn.layer_norm.weight',\n",
       " 'encoder.layers.5.dec_attn.layer_norm.bias',\n",
       " 'encoder.layers.5.pos_ff.CoreNet.0.weight',\n",
       " 'encoder.layers.5.pos_ff.CoreNet.0.bias',\n",
       " 'encoder.layers.5.pos_ff.CoreNet.2.weight',\n",
       " 'encoder.layers.5.pos_ff.CoreNet.2.bias',\n",
       " 'encoder.layers.5.pos_ff.layer_norm.weight',\n",
       " 'encoder.layers.5.pos_ff.layer_norm.bias',\n",
       " 'decoder.layers.1.dec_attn.qkv_net.weight',\n",
       " 'decoder.layers.1.dec_attn.qkv_net.bias',\n",
       " 'decoder.layers.1.dec_attn.o_net.weight',\n",
       " 'decoder.layers.1.dec_attn.layer_norm.weight',\n",
       " 'decoder.layers.1.dec_attn.layer_norm.bias',\n",
       " 'decoder.layers.1.pos_ff.CoreNet.0.weight',\n",
       " 'decoder.layers.1.pos_ff.CoreNet.0.bias',\n",
       " 'decoder.layers.1.pos_ff.CoreNet.2.weight',\n",
       " 'decoder.layers.1.pos_ff.CoreNet.2.bias',\n",
       " 'decoder.layers.1.pos_ff.layer_norm.weight',\n",
       " 'decoder.layers.1.pos_ff.layer_norm.bias',\n",
       " 'decoder.layers.2.dec_attn.qkv_net.weight',\n",
       " 'decoder.layers.2.dec_attn.qkv_net.bias',\n",
       " 'decoder.layers.2.dec_attn.o_net.weight',\n",
       " 'decoder.layers.2.dec_attn.layer_norm.weight',\n",
       " 'decoder.layers.2.dec_attn.layer_norm.bias',\n",
       " 'decoder.layers.2.pos_ff.CoreNet.0.weight',\n",
       " 'decoder.layers.2.pos_ff.CoreNet.0.bias',\n",
       " 'decoder.layers.2.pos_ff.CoreNet.2.weight',\n",
       " 'decoder.layers.2.pos_ff.CoreNet.2.bias',\n",
       " 'decoder.layers.2.pos_ff.layer_norm.weight',\n",
       " 'decoder.layers.2.pos_ff.layer_norm.bias',\n",
       " 'decoder.layers.4.dec_attn.qkv_net.weight',\n",
       " 'decoder.layers.4.dec_attn.qkv_net.bias',\n",
       " 'decoder.layers.4.dec_attn.o_net.weight',\n",
       " 'decoder.layers.4.dec_attn.layer_norm.weight',\n",
       " 'decoder.layers.4.dec_attn.layer_norm.bias',\n",
       " 'decoder.layers.4.pos_ff.CoreNet.0.weight',\n",
       " 'decoder.layers.4.pos_ff.CoreNet.0.bias',\n",
       " 'decoder.layers.4.pos_ff.CoreNet.2.weight',\n",
       " 'decoder.layers.4.pos_ff.CoreNet.2.bias',\n",
       " 'decoder.layers.4.pos_ff.layer_norm.weight',\n",
       " 'decoder.layers.4.pos_ff.layer_norm.bias',\n",
       " 'decoder.layers.5.dec_attn.qkv_net.weight',\n",
       " 'decoder.layers.5.dec_attn.qkv_net.bias',\n",
       " 'decoder.layers.5.dec_attn.o_net.weight',\n",
       " 'decoder.layers.5.dec_attn.layer_norm.weight',\n",
       " 'decoder.layers.5.dec_attn.layer_norm.bias',\n",
       " 'decoder.layers.5.pos_ff.CoreNet.0.weight',\n",
       " 'decoder.layers.5.pos_ff.CoreNet.0.bias',\n",
       " 'decoder.layers.5.pos_ff.CoreNet.2.weight',\n",
       " 'decoder.layers.5.pos_ff.CoreNet.2.bias',\n",
       " 'decoder.layers.5.pos_ff.layer_norm.weight',\n",
       " 'decoder.layers.5.pos_ff.layer_norm.bias']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_to_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "f = open(\"fastpitch_student.json\")\n",
    "student_config = json.load(f)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in layer_to_remove:\n",
    "    del ckpt[\"state_dict\"][key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0283, -0.0030, -0.0215,  ..., -0.0244,  0.0299, -0.0393],\n",
       "        [ 0.0071, -0.0422,  0.0114,  ..., -0.0229, -0.0753, -0.0458],\n",
       "        [-0.0087, -0.0292, -0.0314,  ...,  0.0118,  0.0223,  0.0175],\n",
       "        ...,\n",
       "        [ 0.0154, -0.0119, -0.0037,  ...,  0.0309,  0.0335, -0.0146],\n",
       "        [ 0.0124, -0.0238,  0.0190,  ...,  0.0360, -0.0516, -0.0291],\n",
       "        [ 0.0349,  0.0014, -0.0078,  ..., -0.0241, -0.0313, -0.0046]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt[\"state_dict\"][\"encoder.layers.3.dec_attn.qkv_net.weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in ckpt[\"state_dict\"].keys():\n",
    "    if \"encoder.layers.3\" in layer:\n",
    "        print(layer)\n",
    "        new_layer = layer.replace(\"encoder.layers.3\", \"encoder.layers.1\")\n",
    "        print(new_layer)\n",
    "        ckpt[\"state_dict\"][new_layer] = ckpt[\"state_dict\"].pop(layer)\n",
    "    if \"decoder.layers.3\" in layer:\n",
    "        print(layer)\n",
    "        new_layer = layer.replace(\"decoder.layers.3\", \"decoder.layers.1\")\n",
    "        print(new_layer)\n",
    "        ckpt[\"state_dict\"][new_layer] = ckpt[\"state_dict\"].pop(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ckpt[\"state_dict\"].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models\n",
    "\n",
    "student_model = models.get_model('FastPitch', student_config, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FastPitch(\n",
       "  (encoder): FFTransformer(\n",
       "    (word_emb): Embedding(148, 384, padding_idx=0)\n",
       "    (pos_emb): PositionalEmbedding()\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0-1): 2 x TransformerLayer(\n",
       "        (dec_attn): MultiHeadAttn(\n",
       "          (qkv_net): Linear(in_features=384, out_features=192, bias=True)\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "          (dropatt): Dropout(p=0.1, inplace=False)\n",
       "          (o_net): Linear(in_features=64, out_features=384, bias=False)\n",
       "          (layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (pos_ff): PositionwiseConvFF(\n",
       "          (CoreNet): Sequential(\n",
       "            (0): Conv1d(384, 1536, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): ReLU()\n",
       "            (2): Conv1d(1536, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (duration_predictor): TemporalPredictor(\n",
       "    (layers): Sequential(\n",
       "      (0): ConvReLUNorm(\n",
       "        (conv): Conv1d(384, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): ConvReLUNorm(\n",
       "        (conv): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (fc): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       "  (decoder): FFTransformer(\n",
       "    (pos_emb): PositionalEmbedding()\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0-1): 2 x TransformerLayer(\n",
       "        (dec_attn): MultiHeadAttn(\n",
       "          (qkv_net): Linear(in_features=384, out_features=192, bias=True)\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "          (dropatt): Dropout(p=0.1, inplace=False)\n",
       "          (o_net): Linear(in_features=64, out_features=384, bias=False)\n",
       "          (layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (pos_ff): PositionwiseConvFF(\n",
       "          (CoreNet): Sequential(\n",
       "            (0): Conv1d(384, 1536, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): ReLU()\n",
       "            (2): Conv1d(1536, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pitch_predictor): TemporalPredictor(\n",
       "    (layers): Sequential(\n",
       "      (0): ConvReLUNorm(\n",
       "        (conv): Conv1d(384, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): ConvReLUNorm(\n",
       "        (conv): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (fc): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       "  (pitch_emb): Conv1d(1, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (energy_predictor): TemporalPredictor(\n",
       "    (layers): Sequential(\n",
       "      (0): ConvReLUNorm(\n",
       "        (conv): Conv1d(384, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): ConvReLUNorm(\n",
       "        (conv): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (fc): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       "  (energy_emb): Conv1d(1, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (proj): Linear(in_features=384, out_features=80, bias=True)\n",
       "  (attention): ConvAttention(\n",
       "    (softmax): Softmax(dim=3)\n",
       "    (log_softmax): LogSoftmax(dim=3)\n",
       "    (query_proj): Sequential(\n",
       "      (0): ConvNorm(\n",
       "        (conv): Conv1d(80, 160, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      )\n",
       "      (1): ReLU()\n",
       "      (2): ConvNorm(\n",
       "        (conv): Conv1d(160, 80, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (3): ReLU()\n",
       "      (4): ConvNorm(\n",
       "        (conv): Conv1d(80, 80, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (attn_proj): Conv2d(80, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (key_proj): Sequential(\n",
       "      (0): ConvNorm(\n",
       "        (conv): Conv1d(384, 768, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      )\n",
       "      (1): ReLU()\n",
       "      (2): ConvNorm(\n",
       "        (conv): Conv1d(768, 80, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model.load_state_dict(ckpt[\"state_dict\"])\n",
    "student_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(student_model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\"state_dict\": student_model.state_dict()}, \"student_100.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FastPitch(\n",
       "  (encoder): FFTransformer(\n",
       "    (word_emb): Embedding(148, 384, padding_idx=0)\n",
       "    (pos_emb): PositionalEmbedding()\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0-1): 2 x TransformerLayer(\n",
       "        (dec_attn): MultiHeadAttn(\n",
       "          (qkv_net): Linear(in_features=384, out_features=192, bias=True)\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "          (dropatt): Dropout(p=0.1, inplace=False)\n",
       "          (o_net): Linear(in_features=64, out_features=384, bias=False)\n",
       "          (layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (pos_ff): PositionwiseConvFF(\n",
       "          (CoreNet): Sequential(\n",
       "            (0): Conv1d(384, 1536, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): ReLU()\n",
       "            (2): Conv1d(1536, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (duration_predictor): TemporalPredictor(\n",
       "    (layers): Sequential(\n",
       "      (0): ConvReLUNorm(\n",
       "        (conv): Conv1d(384, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): ConvReLUNorm(\n",
       "        (conv): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (fc): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       "  (decoder): FFTransformer(\n",
       "    (pos_emb): PositionalEmbedding()\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0-1): 2 x TransformerLayer(\n",
       "        (dec_attn): MultiHeadAttn(\n",
       "          (qkv_net): Linear(in_features=384, out_features=192, bias=True)\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "          (dropatt): Dropout(p=0.1, inplace=False)\n",
       "          (o_net): Linear(in_features=64, out_features=384, bias=False)\n",
       "          (layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (pos_ff): PositionwiseConvFF(\n",
       "          (CoreNet): Sequential(\n",
       "            (0): Conv1d(384, 1536, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): ReLU()\n",
       "            (2): Conv1d(1536, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pitch_predictor): TemporalPredictor(\n",
       "    (layers): Sequential(\n",
       "      (0): ConvReLUNorm(\n",
       "        (conv): Conv1d(384, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): ConvReLUNorm(\n",
       "        (conv): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (fc): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       "  (pitch_emb): Conv1d(1, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (energy_predictor): TemporalPredictor(\n",
       "    (layers): Sequential(\n",
       "      (0): ConvReLUNorm(\n",
       "        (conv): Conv1d(384, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): ConvReLUNorm(\n",
       "        (conv): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (fc): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       "  (energy_emb): Conv1d(1, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (proj): Linear(in_features=384, out_features=80, bias=True)\n",
       "  (attention): ConvAttention(\n",
       "    (softmax): Softmax(dim=3)\n",
       "    (log_softmax): LogSoftmax(dim=3)\n",
       "    (query_proj): Sequential(\n",
       "      (0): ConvNorm(\n",
       "        (conv): Conv1d(80, 160, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      )\n",
       "      (1): ReLU()\n",
       "      (2): ConvNorm(\n",
       "        (conv): Conv1d(160, 80, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (3): ReLU()\n",
       "      (4): ConvNorm(\n",
       "        (conv): Conv1d(80, 80, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (attn_proj): Conv2d(80, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (key_proj): Sequential(\n",
       "      (0): ConvNorm(\n",
       "        (conv): Conv1d(384, 768, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      )\n",
       "      (1): ReLU()\n",
       "      (2): ConvNorm(\n",
       "        (conv): Conv1d(768, 80, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_ckpt = torch.load(\"test_student.pt\")\n",
    "student_ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'student_ckpt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m unwrap \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m m: \u001b[39mgetattr\u001b[39m(m, \u001b[39m\"\u001b[39m\u001b[39mmodule\u001b[39m\u001b[39m\"\u001b[39m, m)\n\u001b[0;32m----> 3\u001b[0m torch\u001b[39m.\u001b[39msave({\u001b[39m\"\u001b[39m\u001b[39mstate_dict\u001b[39m\u001b[39m\"\u001b[39m: unwrap(student_ckpt)\u001b[39m.\u001b[39mstate_dict()}, \u001b[39m\"\u001b[39m\u001b[39mtest_student_state_dict.pt\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'student_ckpt' is not defined"
     ]
    }
   ],
   "source": [
    "unwrap = lambda m: getattr(m, \"module\", m)\n",
    "\n",
    "torch.save({\"state_dict\": unwrap(student_ckpt).state_dict()}, \"test_student_state_dict.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FastPitch(\n",
       "  (encoder): FFTransformer(\n",
       "    (word_emb): Embedding(148, 384, padding_idx=0)\n",
       "    (pos_emb): PositionalEmbedding()\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0-1): 2 x TransformerLayer(\n",
       "        (dec_attn): MultiHeadAttn(\n",
       "          (qkv_net): Linear(in_features=384, out_features=192, bias=True)\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "          (dropatt): Dropout(p=0.1, inplace=False)\n",
       "          (o_net): Linear(in_features=64, out_features=384, bias=False)\n",
       "          (layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (pos_ff): PositionwiseConvFF(\n",
       "          (CoreNet): Sequential(\n",
       "            (0): Conv1d(384, 1536, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): ReLU()\n",
       "            (2): Conv1d(1536, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (duration_predictor): TemporalPredictor(\n",
       "    (layers): Sequential(\n",
       "      (0): ConvReLUNorm(\n",
       "        (conv): Conv1d(384, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): ConvReLUNorm(\n",
       "        (conv): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (fc): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       "  (decoder): FFTransformer(\n",
       "    (pos_emb): PositionalEmbedding()\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0-1): 2 x TransformerLayer(\n",
       "        (dec_attn): MultiHeadAttn(\n",
       "          (qkv_net): Linear(in_features=384, out_features=192, bias=True)\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "          (dropatt): Dropout(p=0.1, inplace=False)\n",
       "          (o_net): Linear(in_features=64, out_features=384, bias=False)\n",
       "          (layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (pos_ff): PositionwiseConvFF(\n",
       "          (CoreNet): Sequential(\n",
       "            (0): Conv1d(384, 1536, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): ReLU()\n",
       "            (2): Conv1d(1536, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pitch_predictor): TemporalPredictor(\n",
       "    (layers): Sequential(\n",
       "      (0): ConvReLUNorm(\n",
       "        (conv): Conv1d(384, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): ConvReLUNorm(\n",
       "        (conv): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (fc): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       "  (pitch_emb): Conv1d(1, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (energy_predictor): TemporalPredictor(\n",
       "    (layers): Sequential(\n",
       "      (0): ConvReLUNorm(\n",
       "        (conv): Conv1d(384, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): ConvReLUNorm(\n",
       "        (conv): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (fc): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       "  (energy_emb): Conv1d(1, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (proj): Linear(in_features=384, out_features=80, bias=True)\n",
       "  (attention): ConvAttention(\n",
       "    (softmax): Softmax(dim=3)\n",
       "    (log_softmax): LogSoftmax(dim=3)\n",
       "    (query_proj): Sequential(\n",
       "      (0): ConvNorm(\n",
       "        (conv): Conv1d(80, 160, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      )\n",
       "      (1): ReLU()\n",
       "      (2): ConvNorm(\n",
       "        (conv): Conv1d(160, 80, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (3): ReLU()\n",
       "      (4): ConvNorm(\n",
       "        (conv): Conv1d(80, 80, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (attn_proj): Conv2d(80, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (key_proj): Sequential(\n",
       "      (0): ConvNorm(\n",
       "        (conv): Conv1d(384, 768, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      )\n",
       "      (1): ReLU()\n",
       "      (2): ConvNorm(\n",
       "        (conv): Conv1d(768, 80, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "student_model = models.get_model('FastPitch', student_config, device=\"cpu\")\n",
    "\n",
    "ckpt = torch.load(\"student_100.pt\")\n",
    "print(1)\n",
    "\n",
    "no_pref = lambda sd: {re.sub(\"^module.\", \"\", k): v for k, v in sd.items()}\n",
    "unwrap = lambda m: getattr(m, \"module\", m)\n",
    "\n",
    "unwrap(student_model).load_state_dict(no_pref(ckpt[\"state_dict\"]))\n",
    "# student_model.load_state_dict(ckpt[\"state_dict\"])\n",
    "student_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import itertools\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import re\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from scipy.io.wavfile import write\n",
    "from torch.nn.functional import l1_loss\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import dllogger as DLLogger\n",
    "from dllogger import StdOutBackend, JSONStreamBackend, Verbosity\n",
    "\n",
    "import models\n",
    "from common import gpu_affinity\n",
    "from common.tb_dllogger import (init_inference_metadata, stdout_metric_format,\n",
    "                                unique_log_fpath)\n",
    "from common.text import cmudict\n",
    "from common.text.text_processing import get_text_processing\n",
    "from common.utils import l2_promote\n",
    "from fastpitch.pitch_transform import pitch_transform_custom\n",
    "from hifigan.data_function import MAX_WAV_VALUE, mel_spectrogram\n",
    "from hifigan.models import Denoiser\n",
    "from waveglow import model as glow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference2 import TTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "tts = TTS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mI love you\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/whisper/lib/python3.9/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/dinh.trong.huy/miniconda3/envs/whisper/lib/python3.9/site-packages/torch/utils/_contextlib.py?line=111'>112</a>\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    <a href='file:///home/dinh.trong.huy/miniconda3/envs/whisper/lib/python3.9/site-packages/torch/utils/_contextlib.py?line=112'>113</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    <a href='file:///home/dinh.trong.huy/miniconda3/envs/whisper/lib/python3.9/site-packages/torch/utils/_contextlib.py?line=113'>114</a>\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> <a href='file:///home/dinh.trong.huy/miniconda3/envs/whisper/lib/python3.9/site-packages/torch/utils/_contextlib.py?line=114'>115</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/fastpitch/inference2.py:125\u001b[0m, in \u001b[0;36mTTS.generate_audio\u001b[0;34m(self, text, output, max_wav_value, fade_out, hop_length, sampling_rate)\u001b[0m\n\u001b[1;32m    <a href='file:///home/dinh.trong.huy/fastpitch/inference2.py?line=122'>123</a>\u001b[0m \u001b[39m@torch\u001b[39m\u001b[39m.\u001b[39mno_grad()\n\u001b[1;32m    <a href='file:///home/dinh.trong.huy/fastpitch/inference2.py?line=123'>124</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_audio\u001b[39m(\u001b[39mself\u001b[39m, text, output\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39maudio.wav\u001b[39m\u001b[39m\"\u001b[39m, max_wav_value\u001b[39m=\u001b[39m\u001b[39m32768.0\u001b[39m, fade_out\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, hop_length\u001b[39m=\u001b[39m\u001b[39m256\u001b[39m, sampling_rate\u001b[39m=\u001b[39m\u001b[39m22050\u001b[39m):\n\u001b[0;32m--> <a href='file:///home/dinh.trong.huy/fastpitch/inference2.py?line=124'>125</a>\u001b[0m     mel, mel_lens, \u001b[39m*\u001b[39m_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39minfer(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencode(\u001b[39minput\u001b[39;49m))\n\u001b[1;32m    <a href='file:///home/dinh.trong.huy/fastpitch/inference2.py?line=125'>126</a>\u001b[0m     audios \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvocoder(mel)\u001b[39m.\u001b[39mfloat()\n\u001b[1;32m    <a href='file:///home/dinh.trong.huy/fastpitch/inference2.py?line=126'>127</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdenoiser \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/fastpitch/inference2.py:145\u001b[0m, in \u001b[0;36mTTS.encode\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    <a href='file:///home/dinh.trong.huy/fastpitch/inference2.py?line=143'>144</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mencode\u001b[39m(\u001b[39mself\u001b[39m, text):\n\u001b[0;32m--> <a href='file:///home/dinh.trong.huy/fastpitch/inference2.py?line=144'>145</a>\u001b[0m     \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m [torch\u001b[39m.\u001b[39mLongTensor(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtp\u001b[39m.\u001b[39;49mencode_text(text))]\n\u001b[1;32m    <a href='file:///home/dinh.trong.huy/fastpitch/inference2.py?line=145'>146</a>\u001b[0m     \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m pad_sequence(\u001b[39minput\u001b[39m, batch_first\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    <a href='file:///home/dinh.trong.huy/fastpitch/inference2.py?line=146'>147</a>\u001b[0m     \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/fastpitch/common/text/text_processing.py:127\u001b[0m, in \u001b[0;36mTextProcessing.encode_text\u001b[0;34m(self, text, return_all)\u001b[0m\n\u001b[1;32m    <a href='file:///home/dinh.trong.huy/fastpitch/common/text/text_processing.py?line=124'>125</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mencode_text\u001b[39m(\u001b[39mself\u001b[39m, text, return_all\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    <a href='file:///home/dinh.trong.huy/fastpitch/common/text/text_processing.py?line=125'>126</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexpand_currency:\n\u001b[0;32m--> <a href='file:///home/dinh.trong.huy/fastpitch/common/text/text_processing.py?line=126'>127</a>\u001b[0m         text \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39;49msub(_currency_re, _expand_currency, text)\n\u001b[1;32m    <a href='file:///home/dinh.trong.huy/fastpitch/common/text/text_processing.py?line=127'>128</a>\u001b[0m     text_clean \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclean_text(split) \u001b[39mif\u001b[39;00m split[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m{\u001b[39m\u001b[39m'\u001b[39m \u001b[39melse\u001b[39;00m split\n\u001b[1;32m    <a href='file:///home/dinh.trong.huy/fastpitch/common/text/text_processing.py?line=128'>129</a>\u001b[0m                   \u001b[39mfor\u001b[39;00m split \u001b[39min\u001b[39;00m _arpa_re\u001b[39m.\u001b[39mfindall(text)]\n\u001b[1;32m    <a href='file:///home/dinh.trong.huy/fastpitch/common/text/text_processing.py?line=129'>130</a>\u001b[0m     text_clean \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(text_clean)\n",
      "File \u001b[0;32m~/miniconda3/envs/whisper/lib/python3.9/re.py:210\u001b[0m, in \u001b[0;36msub\u001b[0;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[1;32m    <a href='file:///home/dinh.trong.huy/miniconda3/envs/whisper/lib/python3.9/re.py?line=202'>203</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msub\u001b[39m(pattern, repl, string, count\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, flags\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[1;32m    <a href='file:///home/dinh.trong.huy/miniconda3/envs/whisper/lib/python3.9/re.py?line=203'>204</a>\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return the string obtained by replacing the leftmost\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/dinh.trong.huy/miniconda3/envs/whisper/lib/python3.9/re.py?line=204'>205</a>\u001b[0m \u001b[39m    non-overlapping occurrences of the pattern in string by the\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/dinh.trong.huy/miniconda3/envs/whisper/lib/python3.9/re.py?line=205'>206</a>\u001b[0m \u001b[39m    replacement repl.  repl can be either a string or a callable;\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/dinh.trong.huy/miniconda3/envs/whisper/lib/python3.9/re.py?line=206'>207</a>\u001b[0m \u001b[39m    if a string, backslash escapes in it are processed.  If it is\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/dinh.trong.huy/miniconda3/envs/whisper/lib/python3.9/re.py?line=207'>208</a>\u001b[0m \u001b[39m    a callable, it's passed the Match object and must return\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/dinh.trong.huy/miniconda3/envs/whisper/lib/python3.9/re.py?line=208'>209</a>\u001b[0m \u001b[39m    a replacement string to be used.\"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/dinh.trong.huy/miniconda3/envs/whisper/lib/python3.9/re.py?line=209'>210</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m _compile(pattern, flags)\u001b[39m.\u001b[39;49msub(repl, string, count)\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "tts.generate_audio(\"I love you\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "da2f6209576079fceb0349388ee27bf2a69e7b48d561b5338d33f1571a0f5ea3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.16 ('whisper')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
